{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998c0072",
   "metadata": {},
   "source": [
    "### Jupyter Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  \n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e698f82",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2189ed",
   "metadata": {},
   "source": [
    "### Convert existing Bin file to Hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1117a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_hex(bin_file_path, output_header_path, array_name=\"radix_tree_hex\"):\n",
    "    with open(bin_file_path, 'rb') as bin_file:\n",
    "        binary_data = bin_file.read()\n",
    "\n",
    "    hex_data = binary_data.hex()\n",
    "\n",
    "    with open(output_header_path, 'w') as header_file:\n",
    "        header_file.write('#include <cstdint>\\n\\n')\n",
    "        header_file.write(f'const uint8_t {array_name}[] = {{\\n')\n",
    "\n",
    "        for i in range(0, len(hex_data), 2):\n",
    "            header_file.write(f'0x{hex_data[i:i+2]}, ')\n",
    "            if (i // 2 + 1) % 16 == 0:\n",
    "                header_file.write('\\n')\n",
    "        \n",
    "        header_file.write('\\n};\\n')\n",
    "        header_file.write(f'const unsigned int {array_name}_len = {len(binary_data)};\\n')\n",
    "\n",
    "bin_file_path = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data/bpe-vocab_bookcorpus-small_25000-merges_cleaned-v2_radix-tree_no-markers.bin'\n",
    "output_header_path = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data/bpe-vocab_bookcorpus-small_25000-merges_cleaned-v2_hex-radix-tree_no-markers.h'\n",
    "\n",
    "bin_to_hex(bin_file_path, output_header_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33faa640",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Radix Tree directly in Hex (Serialization and Deserialization being done in hex format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebae690",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_vocab_filepath = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data/bpe-vocab_bookcorpus-30p_25000-merges_cleaned-v2.txt'\n",
    "radix_tree_filepath = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data/bpe-vocab_bookcorpus-30p_25000-merges_cleaned-v2_hex-radix-tree_no-markers.h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadixNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.tokenID = -1\n",
    "\n",
    "class RadixTree:\n",
    "    def __init__(self):\n",
    "        self.root = RadixNode()\n",
    "\n",
    "    def insert(self, word, tokenID):\n",
    "        node = self.root\n",
    "        while word:\n",
    "            for prefix in node.children:\n",
    "                common_length = 0\n",
    "                for i in range(min(len(prefix), len(word))):\n",
    "                    if prefix[i] != word[i]:\n",
    "                        break\n",
    "                    common_length += 1\n",
    "\n",
    "                if common_length > 0:\n",
    "                    if common_length < len(prefix):\n",
    "                        existing_child = node.children.pop(prefix)\n",
    "                        new_node = RadixNode()\n",
    "                        new_node.children[prefix[common_length:]] = existing_child\n",
    "                        node.children[prefix[:common_length]] = new_node\n",
    "                        node = new_node\n",
    "                    else:\n",
    "                        node = node.children[prefix]\n",
    "\n",
    "                    word = word[common_length:]\n",
    "                    break\n",
    "            else:\n",
    "                node.children[word] = RadixNode()\n",
    "                node = node.children[word]\n",
    "                word = \"\"\n",
    "        node.tokenID = tokenID\n",
    "\n",
    "    def serialize_to_hex(self):\n",
    "        def node_to_hex(node):\n",
    "            children_data = ''.join(\n",
    "                struct.pack(f'i{len(prefix)}s', len(prefix), prefix.encode('utf-8')).hex() + node_to_hex(child)\n",
    "                for prefix, child in node.children.items()\n",
    "            )\n",
    "            tokenID_data = struct.pack('i', node.tokenID).hex()\n",
    "            num_children = len(node.children)\n",
    "            num_children_data = struct.pack('i', num_children).hex()\n",
    "            return tokenID_data + num_children_data + children_data\n",
    "\n",
    "        return node_to_hex(self.root)\n",
    "\n",
    "    def save_to_hex_file(self, filename):\n",
    "        hex_data = self.serialize_to_hex()\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(hex_data)\n",
    "            \n",
    "    def traverse(self, word):\n",
    "        node = self.root\n",
    "        while word:\n",
    "            found = False\n",
    "            for prefix, child in node.children.items():\n",
    "                if word.startswith(prefix):\n",
    "                    word = word[len(prefix):]\n",
    "                    node = child\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                return None\n",
    "        return node.tokenID if node.tokenID != -1 else None\n",
    "\n",
    "    def deserialize_from_hex(self, hex_data):\n",
    "        def hex_to_node(data, offset=0):\n",
    "            # Convert the hex string to bytes\n",
    "            byte_data = bytes.fromhex(data)\n",
    "            if offset + 4 > len(byte_data):\n",
    "                raise ValueError(\"Unexpected end of data while reading tokenID\")\n",
    "\n",
    "            tokenID = struct.unpack_from('i', byte_data, offset)[0]\n",
    "            offset += 4\n",
    "\n",
    "            if offset + 4 > len(byte_data):\n",
    "                raise ValueError(\"Unexpected end of data while reading num_children\")\n",
    "\n",
    "            num_children = struct.unpack_from('i', byte_data, offset)[0]\n",
    "            offset += 4\n",
    "\n",
    "            node = RadixNode()\n",
    "            node.tokenID = tokenID\n",
    "\n",
    "            for _ in range(num_children):\n",
    "                if offset + 4 > len(byte_data):\n",
    "                    raise ValueError(\"Unexpected end of data while reading prefix_len\")\n",
    "\n",
    "                prefix_len = struct.unpack_from('i', byte_data, offset)[0]\n",
    "                offset += 4\n",
    "\n",
    "                if offset + prefix_len > len(byte_data):\n",
    "                    raise ValueError(\"Unexpected end of data while reading prefix\")\n",
    "\n",
    "                prefix = struct.unpack_from(f'{prefix_len}s', byte_data, offset)[0]\n",
    "                offset += prefix_len\n",
    "\n",
    "                child, offset = hex_to_node(data, offset)\n",
    "                node.children[prefix.decode('utf-8')] = child  # Decode using utf-8\n",
    "\n",
    "            return node, offset\n",
    "\n",
    "        self.root, _ = hex_to_node(hex_data)\n",
    "\n",
    "    def load_from_hex_file(self, filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            hex_data = file.read().strip()  # Strip to remove any extra spaces or newlines\n",
    "        self.deserialize_from_hex(hex_data)\n",
    "\n",
    "    def get_word_from_id(self, token_id):\n",
    "        return find_word_by_node_id(self.root, token_id)\n",
    "\n",
    "# Helper functions to traverse the Radix Tree\n",
    "def find_word_by_node_id(node, target_id, prefix=''):\n",
    "    if node.tokenID == target_id:\n",
    "        return prefix\n",
    "    for child_prefix, child_node in node.children.items():\n",
    "        result = find_word_by_node_id(child_node, target_id, prefix + child_prefix)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "def find_children_by_node_id(node, target_id):\n",
    "    if node.tokenID == target_id:\n",
    "        return node.children\n",
    "    for child_node in node.children.values():\n",
    "        children = find_children_by_node_id(child_node, target_id)\n",
    "        if children is not None:\n",
    "            return children\n",
    "    return None\n",
    "\n",
    "# Function to clean the word, removing `_` and `</w>` if applicable\n",
    "def clean_word(word):\n",
    "    if word != '_':  # Keep standalone underscore\n",
    "        word = word.lstrip('_')  # Remove leading underscore\n",
    "    word = word.replace('</w>', '')  # Remove end-of-word marker\n",
    "    return word\n",
    "\n",
    "# Function to load the BPE vocabulary and insert it into the Radix Tree\n",
    "def load_and_insert_vocab_into_tree(filename, radix_tree):\n",
    "    with open(filename, 'r') as file:\n",
    "        vocab = file.read().splitlines()\n",
    "\n",
    "    for idx, word in enumerate(vocab):\n",
    "        cleaned_word = clean_word(word)\n",
    "        radix_tree.insert(cleaned_word, idx)\n",
    "\n",
    "# Assuming `bpe_vocab_filepath` contains the vocab and `radix_tree_hex_filepath` is the hex output file.\n",
    "radix_tree = RadixTree()\n",
    "\n",
    "# Load and insert the vocabulary\n",
    "load_and_insert_vocab_into_tree(bpe_vocab_filepath, radix_tree)\n",
    "\n",
    "# Save the Radix tree to a hex file\n",
    "radix_tree.save_to_hex_file(radix_tree_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Radix tree from the hex file\n",
    "radix_tree.load_from_hex_file(radix_tree_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee499a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import struct\n",
    "\n",
    "# Assuming the RadixNode, RadixTree classes, and other helper functions are already defined as before.\n",
    "\n",
    "def clean_input(phrase):\n",
    "    # Remove any spaces at the beginning or end\n",
    "    phrase = phrase.strip()\n",
    "    # Convert to lowercase\n",
    "    phrase = phrase.lower()\n",
    "    # Remove non-ASCII characters\n",
    "    phrase = ''.join(char for char in phrase if ord(char) < 128)\n",
    "    return phrase\n",
    "\n",
    "# Function to split the phrase into words and symbols\n",
    "def tokenize_phrase(phrase):\n",
    "    # Split the phrase into words and standalone symbols\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', phrase, re.UNICODE)\n",
    "    return tokens\n",
    "\n",
    "# Function to encode node IDs to hex\n",
    "def encode_node_ids_to_hex(node_ids):\n",
    "    # Encode to binary first\n",
    "    binary_representation = b''.join(struct.pack('i', node_id) for node_id in node_ids)\n",
    "    # Encode to hex\n",
    "    hex_representation = binary_representation.hex()\n",
    "    return hex_representation\n",
    "\n",
    "# Function to handle user input and perform the encoding\n",
    "def encode_input_phrase(phrase, radix_tree):\n",
    "    cleaned_input = clean_input(phrase)\n",
    "    tokens = tokenize_phrase(cleaned_input)\n",
    "    node_ids = []\n",
    "\n",
    "    for token in tokens:\n",
    "        node_id = radix_tree.traverse(token)\n",
    "        if node_id is not None:\n",
    "            node_ids.append(node_id)\n",
    "        else:\n",
    "            raise ValueError(f\"Token '{token}' not found in the Radix Tree.\")\n",
    "\n",
    "    hex_encoding = encode_node_ids_to_hex(node_ids)\n",
    "    return cleaned_input, node_ids, hex_encoding\n",
    "\n",
    "# Example usage:\n",
    "user_input = \"Hello There 5! How are You?\"\n",
    "\n",
    "# Assuming `radix_tree` is already loaded with the hex data\n",
    "cleaned_input, node_ids, hex_encoding = encode_input_phrase(user_input, radix_tree)\n",
    "\n",
    "print(\"Original Input:\", user_input)\n",
    "print(\"Cleaned Input:\", cleaned_input)\n",
    "print(\"Node IDs:\", node_ids)\n",
    "print(\"Hex Encoding:\", hex_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b50360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hex_to_formatted_header(input_filepath, output_filepath):\n",
    "    # Get the filename without the extension to use in the include guard\n",
    "    filename = os.path.splitext(os.path.basename(output_filepath))[0].upper()\n",
    "    \n",
    "    include_guard = f\"{filename}_H\"\n",
    "\n",
    "    with open(input_filepath, 'r') as infile:\n",
    "        hex_data = infile.read().replace('\\n', '').replace(',', '')\n",
    "\n",
    "    # Prepare the formatted header content\n",
    "    header_content = f\"#ifndef {include_guard}\\n#define {include_guard}\\n\\nconst uint8_t radix_tree_hex[] = {{\\n\"\n",
    "\n",
    "    # Split the hex data into chunks of 2 characters (1 byte)\n",
    "    bytes_list = [hex_data[i:i+2] for i in range(0, len(hex_data), 2)]\n",
    "\n",
    "    # Group the bytes into lines with a max of 12 bytes per line for readability\n",
    "    for i in range(0, len(bytes_list), 12):\n",
    "        line = bytes_list[i:i+12]\n",
    "        formatted_line = \"  \" + \", \".join(f\"0x{byte}\" for byte in line)\n",
    "        if i + 12 < len(bytes_list):\n",
    "            formatted_line += \",\"\n",
    "        header_content += formatted_line + \"\\n\"\n",
    "\n",
    "    # Complete the header content\n",
    "    header_content += \"};\\n\\nconst size_t radix_tree_hex_size = sizeof(radix_tree_hex);\\n\\n\"\n",
    "    header_content += f\"#endif // {include_guard}\\n\"\n",
    "\n",
    "    # Write the formatted header content to the output file\n",
    "    with open(output_filepath, 'w') as outfile:\n",
    "        outfile.write(header_content)\n",
    "\n",
    "# Define the output file path\n",
    "output_filepath = 'bpe-vocab_radix-tree.h'\n",
    "\n",
    "# Convert the hex data to the formatted header\n",
    "convert_hex_to_formatted_header(radix_tree_filepath, output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd1068",
   "metadata": {},
   "source": [
    "### Testing the C Header Hex File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import struct\n",
    "\n",
    "class RadixNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.tokenID = -1\n",
    "\n",
    "class RadixTree:\n",
    "    def __init__(self):\n",
    "        self.root = RadixNode()\n",
    "\n",
    "    def insert(self, word, tokenID):\n",
    "        node = self.root\n",
    "        while word:\n",
    "            for prefix in node.children:\n",
    "                common_length = 0\n",
    "                for i in range(min(len(prefix), len(word))):\n",
    "                    if prefix[i] != word[i]:\n",
    "                        break\n",
    "                    common_length += 1\n",
    "\n",
    "                if common_length > 0:\n",
    "                    if common_length < len(prefix):\n",
    "                        existing_child = node.children.pop(prefix)\n",
    "                        new_node = RadixNode()\n",
    "                        new_node.children[prefix[common_length:]] = existing_child\n",
    "                        node.children[prefix[:common_length]] = new_node\n",
    "                        node = new_node\n",
    "                    else:\n",
    "                        node = node.children[prefix]\n",
    "\n",
    "                    word = word[common_length:]\n",
    "                    break\n",
    "            else:\n",
    "                node.children[word] = RadixNode()\n",
    "                node = node.children[word]\n",
    "                word = \"\"\n",
    "        node.tokenID = tokenID\n",
    "\n",
    "    def traverse(self, word):\n",
    "        node = self.root\n",
    "        while word:\n",
    "            found = False\n",
    "            for prefix, child in node.children.items():\n",
    "                if word.startswith(prefix):\n",
    "                    word = word[len(prefix):]\n",
    "                    node = child\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                return None\n",
    "        return node.tokenID if node.tokenID != -1 else None\n",
    "\n",
    "    def deserialize_from_hex(self, hex_data):\n",
    "        def hex_to_node(data, offset=0):\n",
    "            # Convert the hex string to bytes\n",
    "            byte_data = bytes.fromhex(data)\n",
    "            if offset + 4 > len(byte_data):\n",
    "                raise ValueError(\"Unexpected end of data while reading tokenID\")\n",
    "\n",
    "            tokenID = struct.unpack_from('i', byte_data, offset)[0]\n",
    "            offset += 4\n",
    "\n",
    "            if offset + 4 > len(byte_data):\n",
    "                raise ValueError(\"Unexpected end of data while reading num_children\")\n",
    "\n",
    "            num_children = struct.unpack_from('i', byte_data, offset)[0]\n",
    "            offset += 4\n",
    "\n",
    "            node = RadixNode()\n",
    "            node.tokenID = tokenID\n",
    "\n",
    "            for _ in range(num_children):\n",
    "                if offset + 4 > len(byte_data):\n",
    "                    raise ValueError(\"Unexpected end of data while reading prefix_len\")\n",
    "\n",
    "                prefix_len = struct.unpack_from('i', byte_data, offset)[0]\n",
    "                offset += 4\n",
    "\n",
    "                if offset + prefix_len > len(byte_data):\n",
    "                    raise ValueError(\"Unexpected end of data while reading prefix\")\n",
    "\n",
    "                prefix = struct.unpack_from(f'{prefix_len}s', byte_data, offset)[0]\n",
    "                offset += prefix_len\n",
    "\n",
    "                child, offset = hex_to_node(data, offset)\n",
    "                node.children[prefix.decode('utf-8')] = child  # Decode using utf-8\n",
    "\n",
    "            return node, offset\n",
    "\n",
    "        self.root, _ = hex_to_node(hex_data)\n",
    "\n",
    "    def load_from_hex_file(self, filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Extract the hex data from the C array in the .h file\n",
    "        hex_data = re.findall(r'0x[0-9a-fA-F]{2}', content)\n",
    "        hex_data = ''.join(h[2:] for h in hex_data)  # Remove \"0x\" and concatenate\n",
    "\n",
    "        self.deserialize_from_hex(hex_data)\n",
    "\n",
    "    def get_word_from_id(self, token_id):\n",
    "        return find_word_by_node_id(self.root, token_id)\n",
    "\n",
    "# Helper functions to traverse the Radix Tree\n",
    "def find_word_by_node_id(node, target_id, prefix=''):\n",
    "    if node.tokenID == target_id:\n",
    "        return prefix\n",
    "    for child_prefix, child_node in node.children.items():\n",
    "        result = find_word_by_node_id(child_node, target_id, prefix + child_prefix)\n",
    "        if result:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "def find_children_by_node_id(node, target_id):\n",
    "    if node.tokenID == target_id:\n",
    "        return node.children\n",
    "    for child_node in node.children.values():\n",
    "        children = find_children_by_node_id(child_node, target_id)\n",
    "        if children is not None:\n",
    "            return children\n",
    "    return None\n",
    "\n",
    "def clean_input(phrase):\n",
    "    phrase = phrase.strip().lower()\n",
    "    phrase = ''.join(char for char in phrase if ord(char) < 128)\n",
    "    return phrase\n",
    "\n",
    "def tokenize_phrase(phrase):\n",
    "    return re.findall(r'\\w+|[^\\w\\s]', phrase, re.UNICODE)\n",
    "\n",
    "def encode_node_ids_to_hex(node_ids):\n",
    "    binary_representation = b''.join(struct.pack('i', node_id) for node_id in node_ids)\n",
    "    return binary_representation.hex()\n",
    "\n",
    "def encode_input_phrase(phrase, radix_tree):\n",
    "    cleaned_input = clean_input(phrase)\n",
    "    tokens = tokenize_phrase(cleaned_input)\n",
    "    node_ids = []\n",
    "\n",
    "    for token in tokens:\n",
    "        node_id = radix_tree.traverse(token)\n",
    "        if node_id is not None:\n",
    "            node_ids.append(node_id)\n",
    "        else:\n",
    "            raise ValueError(f\"Token '{token}' not found in the Radix Tree.\")\n",
    "\n",
    "    hex_encoding = encode_node_ids_to_hex(node_ids)\n",
    "    return cleaned_input, node_ids, hex_encoding\n",
    "\n",
    "# Load the Radix tree from the hex data in the .h file\n",
    "radix_tree_hex_filepath = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data_processing_python/bpe-vocab_radix-tree.h'\n",
    "radix_tree = RadixTree()\n",
    "radix_tree.load_from_hex_file(radix_tree_hex_filepath)\n",
    "\n",
    "# Example usage: Encode an input phrase\n",
    "user_input = \"buddies\"\n",
    "cleaned_input, node_ids, hex_encoding = encode_input_phrase(user_input, radix_tree)\n",
    "\n",
    "print(\"Original Input:\", user_input)\n",
    "print(\"Cleaned Input:\", cleaned_input)\n",
    "print(\"Node IDs:\", node_ids)\n",
    "print(\"Hex Encoding:\", hex_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4cb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0771a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadixNode:\n",
    "    def __init__(self, tokenID=-1):\n",
    "        self.children = {}\n",
    "        self.tokenID = tokenID\n",
    "\n",
    "class RadixTree:\n",
    "    def __init__(self):\n",
    "        self.root = RadixNode()\n",
    "\n",
    "    def insert(self, word, tokenID):\n",
    "        node = self.root\n",
    "        while word:\n",
    "            for prefix in node.children:\n",
    "                common_length = 0\n",
    "                for i in range(min(len(prefix), len(word))):\n",
    "                    if prefix[i] != word[i]:\n",
    "                        break\n",
    "                    common_length += 1\n",
    "\n",
    "                if common_length > 0:\n",
    "                    if common_length < len(prefix):\n",
    "                        existing_child = node.children.pop(prefix)\n",
    "                        new_node = RadixNode()\n",
    "                        new_node.children[prefix[common_length:]] = existing_child\n",
    "                        node.children[prefix[:common_length]] = new_node\n",
    "                        node = new_node\n",
    "                    else:\n",
    "                        node = node.children[prefix]\n",
    "\n",
    "                    word = word[common_length:]\n",
    "                    break\n",
    "            else:\n",
    "                node.children[word] = RadixNode()\n",
    "                node = node.children[word]\n",
    "                word = \"\"\n",
    "        node.tokenID = tokenID\n",
    "\n",
    "    def generate_c_code(self, max_children):\n",
    "        def escape_special_characters(token):\n",
    "            token = token.replace('\\\\', '\\\\\\\\')\n",
    "            token = token.replace('\\\"', '\\\\\\\"')\n",
    "            token = token.replace('\\'', '\\\\\\'')\n",
    "            token = token.replace('\\n', '\\\\n')\n",
    "            token = token.replace('\\r', '\\\\r')\n",
    "            token = token.replace('\\t', '\\\\t')\n",
    "            token = token.replace('<space>', ' ')  # Convert <space> to whitespace\n",
    "            return token\n",
    "\n",
    "        def node_to_c_code(node, node_name, child_index=0):\n",
    "            # First declare all the children\n",
    "            child_code = \"\"\n",
    "            for i, (prefix, child) in enumerate(node.children.items()):\n",
    "                child_name = f\"{node_name}_child{i}\"\n",
    "                child_code += node_to_c_code(child, child_name)\n",
    "            \n",
    "            # Then declare the node itself\n",
    "            code = f\"RadixNode {node_name} = {{.tokenID = {node.tokenID}, .children = {{\\n\"\n",
    "            for i, (prefix, child) in enumerate(node.children.items()):\n",
    "                escaped_prefix = escape_special_characters(prefix)\n",
    "                child_name = f\"{node_name}_child{i}\"\n",
    "                code += f'  {{\"{escaped_prefix}\", &{child_name}}},\\n'\n",
    "            code += f\"}}}};\\n\"\n",
    "\n",
    "            return child_code + code\n",
    "\n",
    "        return node_to_c_code(self.root, \"root\")\n",
    "\n",
    "    def save_to_c_file(self, filename, max_children):\n",
    "        c_code = self.generate_c_code(max_children)\n",
    "        header_content = f\"\"\"\n",
    "#ifndef RADIX_TREE_H\n",
    "#define RADIX_TREE_H\n",
    "\n",
    "typedef struct RadixNode {{\n",
    "    int tokenID;\n",
    "    struct {{\n",
    "        const char *prefix;\n",
    "        struct RadixNode *node;\n",
    "    }} children[{max_children}];  // Adjusted based on the max children needed\n",
    "}} RadixNode;\n",
    "\n",
    "{c_code}\n",
    "\n",
    "#endif // RADIX_TREE_H\n",
    "\"\"\"\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(header_content)\n",
    "\n",
    "    def find_max_children(self):\n",
    "        def max_children(node):\n",
    "            if not node.children:\n",
    "                return 0\n",
    "            return max(len(node.children), max(max_children(child) for child in node.children.values()))\n",
    "\n",
    "        return max_children(self.root)\n",
    "\n",
    "# Function to clean the word, removing `_` and `</w>` if applicable\n",
    "def clean_word(word):\n",
    "    if word != '_':  # Keep standalone underscore\n",
    "        word = word.lstrip('_')  # Remove leading underscore\n",
    "    word = word.replace('</w>', '')  # Remove end-of-word marker\n",
    "    return word\n",
    "\n",
    "# Function to load the BPE vocabulary and insert it into the Radix Tree\n",
    "def load_and_insert_vocab_into_tree(filename, radix_tree):\n",
    "    with open(filename, 'r') as file:\n",
    "        vocab = file.read().splitlines()\n",
    "\n",
    "    for idx, word in enumerate(vocab):\n",
    "        cleaned_word = clean_word(word)\n",
    "        radix_tree.insert(cleaned_word, idx)\n",
    "\n",
    "# Assuming `bpe_vocab_filepath` contains the vocab and `radix_tree_c_filepath` is the C header output file.\n",
    "bpe_vocab_filepath = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data/bpe-vocab_bookcorpus-small_25000-merges_cleaned-v2.txt'\n",
    "radix_tree_c_filepath = 'radix_tree.h'\n",
    "\n",
    "# Initialize the radix tree\n",
    "radix_tree = RadixTree()\n",
    "\n",
    "# Load and insert the vocabulary\n",
    "load_and_insert_vocab_into_tree(bpe_vocab_filepath, radix_tree)\n",
    "\n",
    "# Calculate the maximum number of children any node has\n",
    "max_children = radix_tree.find_max_children()\n",
    "\n",
    "# Save the Radix tree to a C file, passing the max_children value\n",
    "radix_tree.save_to_c_file(radix_tree_c_filepath, max_children)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tf-gpu-m1)",
   "language": "python",
   "name": "tf-gpu-m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
