{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baed7d9c",
   "metadata": {},
   "source": [
    "### Jupyter Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e227f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))  \n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929929f",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe349aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445bd4ac",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_filepath = '/Users/ciprian/Desktop/Projects/Microcontroller Tokenizer/microcontroller-tokenizer/data/bpe-vocab_bookcorpus-small_100000-merges_cleaned_radix-tree_no-markers.h'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea6e24",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the byte array from the .h file\n",
    "def load_byte_array_from_h_file(h_file_path):\n",
    "    with open(h_file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # Use regex to find the array definition\n",
    "    array_match = re.search(r\"unsigned char.*\\[\\] = \\{(.*?)\\};\", content, re.DOTALL)\n",
    "    \n",
    "    if not array_match:\n",
    "        raise ValueError(\"No byte array found in the .h file.\")\n",
    "    \n",
    "    # Extract the array contents and convert them to a bytes object\n",
    "    byte_array = array_match.group(1)\n",
    "    byte_values = bytes(int(b, 16) for b in re.findall(r'0x[0-9a-fA-F]+', byte_array))\n",
    "    \n",
    "    return byte_values\n",
    "\n",
    "# Inspect first 32 bytes\n",
    "inspect_byte_array(byte_array, 0, 32)\n",
    "\n",
    "# Step 2: Inspect the byte array in small chunks\n",
    "def inspect_byte_array(byte_array, start=0, num_bytes=16):\n",
    "    print(f\"Bytes from {start} to {start + num_bytes}: {byte_array[start:start + num_bytes]}\")\n",
    "\n",
    "# Inspect the first 16 bytes to start with\n",
    "inspect_byte_array(byte_array, 0, 16)\n",
    "\n",
    "# Step 3: Manually parse the first node with additional debugging\n",
    "def parse_first_node(byte_array):\n",
    "    offset = 0\n",
    "    buffer_size = len(byte_array)\n",
    "    \n",
    "    print(f\"Buffer size: {buffer_size}\")\n",
    "    \n",
    "    if offset + 8 > buffer_size:\n",
    "        raise ValueError(\"Insufficient data to read tokenID and num_children\")\n",
    "    \n",
    "    tokenID, num_children = struct.unpack_from('>II', byte_array, offset)\n",
    "    print(f\"Token ID: {tokenID}, Number of Children: {num_children}\")\n",
    "    offset += 8\n",
    "    print(f\"New Offset: {offset}\")\n",
    "    \n",
    "    for child_index in range(num_children):\n",
    "        if offset + 1 > buffer_size:\n",
    "            raise ValueError(\"Insufficient data to read prefix length\")\n",
    "        \n",
    "        prefix_length = struct.unpack_from('B', byte_array, offset)[0]\n",
    "        print(f\"Prefix Length: {prefix_length}\")\n",
    "        offset += 1\n",
    "        print(f\"Offset after reading prefix length: {offset}\")\n",
    "        \n",
    "        if offset + prefix_length > buffer_size:\n",
    "            raise ValueError(\"Insufficient data to read prefix\")\n",
    "        \n",
    "        prefix = byte_array[offset:offset + prefix_length]\n",
    "        print(f\"Prefix: {prefix}\")\n",
    "        offset += prefix_length\n",
    "        print(f\"Offset after reading prefix: {offset}\")\n",
    "        \n",
    "        if offset + 8 > buffer_size:\n",
    "            raise ValueError(\"Insufficient data to read child tokenID and num_children\")\n",
    "        \n",
    "        child_tokenID, child_num_children = struct.unpack_from('>II', byte_array, offset)\n",
    "        print(f\"Child Token ID: {child_tokenID}, Child Number of Children: {child_num_children}\")\n",
    "        offset += 8\n",
    "        print(f\"Offset after reading child node: {offset}\")\n",
    "\n",
    "# Parse the first node\n",
    "parse_first_node(byte_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create the RadixTree and traverse logic\n",
    "class RadixNode:\n",
    "    def __init__(self, tokenID, children):\n",
    "        self.tokenID = tokenID\n",
    "        self.children = children\n",
    "\n",
    "class RadixTree:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.root = self.load_tree_iterative()\n",
    "\n",
    "    def load_tree_iterative(self):\n",
    "        offset = 0\n",
    "        stack = []\n",
    "        root_node = None\n",
    "        current_node = None\n",
    "\n",
    "        while offset < len(self.data):\n",
    "            tokenID, num_children = struct.unpack_from('>II', self.data, offset)\n",
    "            offset += 8\n",
    "            children = {}\n",
    "\n",
    "            # If there's a node on the stack, this becomes its child\n",
    "            if stack:\n",
    "                parent_node, prefix_length, expected_children = stack[-1]\n",
    "                prefix = self.data[offset:offset + prefix_length]\n",
    "                offset += prefix_length\n",
    "                children = parent_node.children\n",
    "                children[prefix] = RadixNode(tokenID, {})\n",
    "                current_node = children[prefix]\n",
    "\n",
    "                expected_children -= 1\n",
    "                if expected_children == 0:\n",
    "                    stack.pop()\n",
    "\n",
    "            else:\n",
    "                # If there's no parent, this is the root node\n",
    "                root_node = RadixNode(tokenID, {})\n",
    "                current_node = root_node\n",
    "\n",
    "            # If this node has children, push it to the stack\n",
    "            if num_children > 0:\n",
    "                stack.append((current_node, struct.unpack_from('B', self.data, offset)[0], num_children))\n",
    "                offset += 1  # Move past the prefix length byte\n",
    "\n",
    "        return root_node\n",
    "\n",
    "    def traverse(self, word):\n",
    "        node = self.root\n",
    "        word = word.encode('utf-8')  # Convert the input word to binary for comparison\n",
    "        while word:\n",
    "            found = False\n",
    "            for prefix, child in node.children.items():\n",
    "                if word.startswith(prefix):\n",
    "                    word = word[len(prefix):]\n",
    "                    node = child\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                return -1\n",
    "        return node.tokenID\n",
    "\n",
    "# Step 3: Clean input function\n",
    "def clean_input(phrase):\n",
    "    # Remove leading/trailing whitespace\n",
    "    phrase = phrase.strip()\n",
    "    # Convert to lowercase\n",
    "    phrase = phrase.lower()\n",
    "    # Remove non-ASCII characters\n",
    "    phrase = ''.join(c for c in phrase if ord(c) < 128)\n",
    "    return phrase\n",
    "\n",
    "# Initialize RadixTree with the loaded byte array\n",
    "radixTree = RadixTree(byte_array)\n",
    "\n",
    "# Step 4: Take user input and simulate\n",
    "def simulate_user_input():\n",
    "    input_phrase = input(\"Enter a phrase: \")\n",
    "    cleaned_input = clean_input(input_phrase)\n",
    "    print(f\"Cleaned Input: {cleaned_input}\")\n",
    "\n",
    "    nodeID = radixTree.traverse(cleaned_input)\n",
    "    \n",
    "    if nodeID != -1:\n",
    "        print(f\"Node ID: {nodeID}\")\n",
    "    else:\n",
    "        print(\"Phrase not found in the tree.\")\n",
    "\n",
    "simulate_user_input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tf-gpu-m1)",
   "language": "python",
   "name": "tf-gpu-m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
